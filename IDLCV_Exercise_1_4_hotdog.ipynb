{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4 Hotdog -- no hotdog\n",
    "This is the first poster hand-in exercise for the course. Please see the associated PDF for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "DRIhx7PugJy3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "from enum import Enum\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import v2 as transformsV2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35PhqXpWUZ7I"
   },
   "source": [
    "We always check that we are running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ic_gOv_pUZeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAj64PJYgJzC"
   },
   "source": [
    "We provide you with a class that can load the *hotdog/not hotdog* dataset you should use from /dtu/datasets1/02516/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\jacop\\Desktop\\DTU\\Intro_to_Deep_Learning_in_Computer_Vision\\Exercises\\Project_1\\HotDogOrNot\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_home = \"/zhome/f9/0/168881/Desktop/WindTurbineImagesCategorization/TransferLearning/TorchvisionModels\"\n",
    "hyperparameters = {\n",
    "    \"number of classes\": 2,\n",
    "    \"device\": device,\n",
    "    \"epochs\": [1, 1, 1],\n",
    "    \"batch size\": 6,\n",
    "    \"learning rate\": [0.001, 0.0001, 0.00001],\n",
    "    \"number of epochs\": 3,\n",
    "    \"image size\": (224, 224),\n",
    "    \"backbones\": \"mobilenet_v3_large\",  # Here we can change the model to use\n",
    "    \"torch home\": \"C:\\\\Users\\\\jacop\\\\Desktop\\\\DTU\\\\Intro_to_Deep_Learning_in_Computer_Vision\\\\Exercises\\\\Project_1\\\\HotDogOrNot\\\\TorchvisionModels\",\n",
    "    \"network name\": \"Mads\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight decay\": 0.0005,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"scheduler\": \"No\",\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"epsilon\": 1e-08,\n",
    "    \"step size\": [1, 1, 1],\n",
    "    \"gamma\": [0.1, 0.1, 0.1],\n",
    "}\n",
    "\n",
    "train_transform = transformsV2.Compose([transformsV2.Resize(hyperparameters[\"image size\"]),\n",
    "                                        transformsV2.RandomVerticalFlip(p=0.5),\n",
    "                                        transformsV2.RandomHorizontalFlip(\n",
    "                                            p=0.5),\n",
    "                                        transformsV2.RandomAdjustSharpness(\n",
    "                                            sharpness_factor=2, p=0.5),\n",
    "                                        transformsV2.RandomAutocontrast(p=0.5),\n",
    "                                        transformsV2.ColorJitter(\n",
    "                                            brightness=0.25, saturation=0.20),\n",
    "                                        # Replace deprecated ToTensor()\n",
    "                                        transformsV2.ToImage(),\n",
    "                                        transformsV2.ToDtype(torch.float32, scale=True)])\n",
    "test_transform = transformsV2.Compose([transformsV2.Resize(hyperparameters[\"image size\"]),\n",
    "                                       # Replace deprecated ToTensor()\n",
    "                                       transformsV2.ToImage(),\n",
    "                                       transformsV2.ToDtype(torch.float32, scale=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "4mUlnOuzgJzF"
   },
   "outputs": [],
   "source": [
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transforms, data_path='..\\\\..\\\\data\\\\hotdog_nothotdog'):\n",
    "        'Initialization'\n",
    "        self.transforms = transforms\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(\n",
    "            data_path + '/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transforms(image)\n",
    "        return X, y\n",
    "\n",
    "    def set_transforms(self, transforms):\n",
    "        self.transforms = transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JewkmhKlgJzN"
   },
   "source": [
    "Below is the simple way of converting the images to something that can be fed through a network.\n",
    "Feel free to use something other than $128\\times128$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ZcilkL3dgJzP"
   },
   "outputs": [],
   "source": [
    "trainset = Hotdog_NotHotdog(train=True, transforms=train_transform)\n",
    "\n",
    "# Define the sizes for train and validation splits\n",
    "train_size = int(0.8 * len(trainset))  # 80% for training\n",
    "val_size = len(trainset) - train_size   # 20% for validation\n",
    "\n",
    "# Split the train dataset into train and val\n",
    "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
    "# TODO: Check if this is correct\n",
    "val_dataset.dataset.set_transforms(test_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=hyperparameters[\"batch size\"], shuffle=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=hyperparameters[\"batch size\"], shuffle=False)\n",
    "testset = Hotdog_NotHotdog(train=False, transforms=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=hyperparameters[\"batch size\"],\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho-YRb6HgJzZ"
   },
   "source": [
    "Let's look at some images from our data \n",
    "\n",
    "Commented because I don't wanna see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Sm4Ara7dgJza"
   },
   "outputs": [],
   "source": [
    "# images, labels = next(iter(train_loader))\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# for i in range(21):\n",
    "#     plt.subplot(5, 7, i+1)\n",
    "#     plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1))\n",
    "#     plt.title(['hotdog', 'not hotdog'][labels[i].item()])\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12N0EYYsQPhJ"
   },
   "source": [
    "Now create a model and train it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TORCH_HOME'] = hyperparameters[\"torch home\"]\n",
    "os.makedirs(hyperparameters[\"torch home\"], exist_ok=True)\n",
    "\n",
    "\n",
    "class FineTuneMode(Enum):\n",
    "    \"\"\" Indicatea which layers we want to train during fine-tuning \"\"\"\n",
    "    \" Just the new added layers \"\n",
    "    NEW_LAYERS = 1\n",
    "    \" Just the classifier \"\n",
    "    CLASSIFIER = 2\n",
    "    \"Train all the layers \"\n",
    "    ALL_LAYERS = 3\n",
    "\n",
    "\n",
    "class MultiModel(nn.Module):\n",
    "    \"\"\" Custom class that wraps a torchvision model and provides methods to fine-tune \"\"\"\n",
    "\n",
    "    def __init__(self, backbone, hyperparameters, load_pretrained=False):\n",
    "        super().__init__()\n",
    "        assert backbone in hyperparameters[\"backbones\"], f\"Invalid backbone: {\n",
    "            backbone}\"\n",
    "        self.backbone = hyperparameters[\"backbones\"][0]\n",
    "        self.pretrained_model = None\n",
    "        self.classifier_layers = []\n",
    "        self.new_layers = []\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "        if backbone == \"mobilenet_v3_large\":\n",
    "            if load_pretrained:\n",
    "                self.pretrained_model = torchvision.models.mobilenet_v3_large(\n",
    "                    weights=torchvision.models.MobileNet_V3_Large_Weights.IMAGENET1K_V2)\n",
    "            else:\n",
    "                self.pretrained_model = torchvision.models.mobilenet_v3_large(\n",
    "                    weights=None)\n",
    "\n",
    "            self.classifier_layers = [self.pretrained_model.classifier]\n",
    "            # Replace the final layer with a classifier for 2 classes\n",
    "            self.pretrained_model.classifier[3] = nn.Linear(\n",
    "                in_features=1280, out_features=self.hyperparameters[\"number of classes\"], bias=True)\n",
    "            self.new_layers = [self.pretrained_model.classifier[3]]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid backbone: {backbone}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pretrained_model(x)  # type: ignore\n",
    "\n",
    "    def fine_tune(self, mode: FineTuneMode):\n",
    "        \" Fine-tune the model according to the specified mode using the requires_grad parameter \"\n",
    "        model = self.pretrained_model\n",
    "        for parameter in model.parameters():  # type: ignore\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "        if mode is FineTuneMode.NEW_LAYERS:\n",
    "            for layer in self.new_layers:\n",
    "                for parameter in layer.parameters():\n",
    "                    parameter.requires_grad = True\n",
    "        elif mode is FineTuneMode.CLASSIFIER:\n",
    "            for layer in self.classifier_layers:\n",
    "                for parameter in layer.parameters():\n",
    "                    parameter.requires_grad = True\n",
    "        elif mode is FineTuneMode.ALL_LAYERS:\n",
    "            for parameter in model.parameters():  # type: ignore\n",
    "                parameter.requires_grad = True\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "        print(f\"Ready to fine-tune the model, with the {mode} set to train\")\n",
    "\n",
    "    def count_parameters(self):\n",
    "        total_params = sum(parameter.numel()\n",
    "                           for parameter in self.parameters())\n",
    "        print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable), total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "\n",
    "def train_net(model, loss_function, device, dataloader_train, dataloader_validation, optimizer, hyper_parameters, logger, scheduler, state, name=\"default\"):\n",
    "    epochs = hyper_parameters[\"epochs\"]\n",
    "\n",
    "    validation_loss = 0\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        \"\"\"    Train step for one batch of data    \"\"\"\n",
    "        training_loop = create_tqdm_bar(\n",
    "            dataloader_train, desc=f'Training Epoch [{epoch+1}/{epochs}]')\n",
    "\n",
    "        training_loss = 0\n",
    "        model.train()  # Set the model to training mode\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad()  # Reset the parameter gradients for the current minibatch iteration\n",
    "\n",
    "            images, labels = batch\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass, backward pass and optimizer step\n",
    "            predicted_labels = model(images)\n",
    "            loss_train = loss_function(predicted_labels, labels)\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss and calculate the accuracy of predictions\n",
    "            training_loss += loss_train.item()\n",
    "\n",
    "            # Running train accuracy\n",
    "            _, predicted = predicted_labels.max(1)\n",
    "            num_correct = (predicted == labels).sum()\n",
    "            train_accuracy = float(num_correct)/float(images.shape[0])\n",
    "\n",
    "            training_loop.set_postfix(train_loss=\"{:.8f}\".format(\n",
    "                training_loss / (train_iteration + 1)), val_loss=\"{:.8f}\".format(validation_loss))\n",
    "\n",
    "            logger.add_scalar(f'{name}/Train loss_{state}', loss_train.item(),\n",
    "                              epoch*len(dataloader_train)+train_iteration)\n",
    "            logger.add_scalar(f'{name}/Train accuracy_{state}',\n",
    "                              train_accuracy, epoch*len(dataloader_train)+train_iteration)\n",
    "\n",
    "        \"\"\"    Validation step for one batch of data    \"\"\"\n",
    "        val_loop = create_tqdm_bar(\n",
    "            dataloader_validation, desc=f'Validation Epoch [{epoch+1}/{epochs}]')\n",
    "        validation_loss = 0\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                images, labels = batch\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(images)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss_val = loss_function(output, labels)\n",
    "\n",
    "                validation_loss += loss_val.item()\n",
    "\n",
    "                val_loop.set_postfix(val_loss=\"{:.8f}\".format(\n",
    "                    validation_loss/(val_iteration+1)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                logger.add_scalar(f'{name}/Validation loss_{state}', validation_loss/(\n",
    "                    val_iteration+1), epoch*len(dataloader_validation)+val_iteration)\n",
    "\n",
    "        # This value is for the progress bar of the training loop.\n",
    "        validation_loss /= len(dataloader_validation)\n",
    "        add_layer_weight_histograms(model, logger, name)\n",
    "\n",
    "        logger.add_scalars(f'{name}/Combined_{state}', {'Validation loss': validation_loss,\n",
    "                                                        'Train loss': training_loss/len(dataloader_train)}, epoch)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            print(f\"Current learning rate: {scheduler.get_last_lr()}\")\n",
    "\n",
    "\n",
    "def rescale_0_1(image):\n",
    "    \"\"\"Rescale pixel values to range [0, 1] for visualization purposes only.\"\"\"\n",
    "    min_val = image.min()\n",
    "    max_val = image.max()\n",
    "    rescaled_image = (image-min_val)/abs(max_val-min_val)\n",
    "    return rescaled_image\n",
    "\n",
    "\n",
    "def filter_hp_from_list(original_dict, state):\n",
    "    new_dict = {}\n",
    "    for key, value in original_dict.items():\n",
    "        if isinstance(value, list):\n",
    "            new_dict[key] = value[state]\n",
    "        else:\n",
    "            new_dict[key] = value\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def add_layer_weight_histograms(model, logger, model_name):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            logger.add_histogram(f\"{model_name}/{name}.weights\", module.weight)\n",
    "\n",
    "\n",
    "def save_misclassified_images(misclassified, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for idx, (images, labels, predictions) in enumerate(misclassified):\n",
    "        # Save only when true and predicted labels are different\n",
    "        if labels != predictions:\n",
    "            image = rescale_0_1(images)\n",
    "            image = TF.to_pil_image(image)\n",
    "            # Naming format: misclassified_<index>_true_<true label>_predicted_<predicted label>.png\n",
    "            image_name = f\"misclassified_{idx}_true_lable_{\n",
    "                labels}_predicted_label_{predictions}.png\"\n",
    "            image_path = os.path.join(save_dir, image_name)\n",
    "            image.save(image_path)\n",
    "\n",
    "\n",
    "def check_accuracy(model, dataloader, DEVICE, save_dir=None):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    misclassified = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            image, label = data\n",
    "            label = label.type(torch.LongTensor)\n",
    "\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "\n",
    "            scores = model(image)\n",
    "\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == label).sum()\n",
    "\n",
    "            num_samples += predictions.size(0)\n",
    "            y_pred.extend(predictions.cpu().tolist())  # Save Prediction\n",
    "            label = label.data.cpu().numpy()\n",
    "\n",
    "            y_true.extend(label)  # Save Truth\n",
    "\n",
    "            misclassified_mask = predictions != torch.tensor(\n",
    "                label, device=predictions.device)\n",
    "            if misclassified_mask.any():  # Check if there are any misclassified images\n",
    "                misclassified_images = image[misclassified_mask]\n",
    "                misclassified_labels = label[misclassified_mask]\n",
    "                misclassified_predictions = predictions[misclassified_mask].cpu(\n",
    "                ).numpy()\n",
    "\n",
    "                # Append only misclassified examples\n",
    "                misclassified.extend(\n",
    "                    zip(misclassified_images, misclassified_labels, misclassified_predictions))\n",
    "\n",
    "    accuracy = float(num_correct)/float(num_samples)\n",
    "    print(f\"Got {num_correct}/{num_samples} with accuracy {accuracy * 100:.3f}%\")\n",
    "    classes = ('HotDog', 'NotHotDog')\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in classes],\n",
    "                         columns=[i for i in classes])\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sn.set_theme(font_scale=1.2)\n",
    "    sn.heatmap(df_cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "               xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix', fontsize=20, fontweight='bold', color='red')\n",
    "    if save_dir:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        plt.savefig(os.path.join(save_dir, 'confusion_matrix.png'))\n",
    "        plt.close()\n",
    "\n",
    "    save_misclassified_images(misclassified, save_dir)\n",
    "\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def automatic_fine_tune(hyper_parameters, modeltype, device, loss_function, dataloader_train, dataloader_validation, dataloader_test, ChoiceOptimizer, ChoiceScheduler):\n",
    "    STATE = 0\n",
    "    new_hp = filter_hp_from_list(hyper_parameters, STATE)\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    logs_dir = f'run_{new_hp[\"network name\"]}_{\n",
    "        ChoiceOptimizer}_Scheduler_{ChoiceScheduler}'\n",
    "    dir = os.path.join(cwd, logs_dir)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    logger = SummaryWriter(logs_dir)\n",
    "\n",
    "    # Train new layers\n",
    "    model = MultiModel(modeltype, new_hp, load_pretrained=True)\n",
    "    model.fine_tune(FineTuneMode.NEW_LAYERS)\n",
    "    model.to(device)\n",
    "    Train_net_wrapper(device, \"NEW LAYERS\", loss_function, dataloader_train,\n",
    "                      dataloader_validation, new_hp, logger, model, ChoiceOptimizer, ChoiceScheduler)\n",
    "\n",
    "    # Train classifier layers\n",
    "    model.fine_tune(FineTuneMode.CLASSIFIER)\n",
    "    STATE += 1\n",
    "    new_hp = filter_hp_from_list(hyper_parameters, STATE)\n",
    "    Train_net_wrapper(device, \"CLASSIFIER\", loss_function, dataloader_train,\n",
    "                      dataloader_validation, new_hp, logger, model, ChoiceOptimizer, ChoiceScheduler)\n",
    "\n",
    "    # Fine tune all layers\n",
    "    model.fine_tune(FineTuneMode.ALL_LAYERS)\n",
    "    STATE += 1\n",
    "    new_hp = filter_hp_from_list(hyper_parameters, STATE)\n",
    "    Train_net_wrapper(device, \"ALL LAYERS\", loss_function, dataloader_train,\n",
    "                      dataloader_validation, new_hp, logger, model, ChoiceOptimizer, ChoiceScheduler)\n",
    "\n",
    "    # Check accuracy and save model\n",
    "    accuracy = check_accuracy(model, dataloader_test, device, os.path.join(\n",
    "        logs_dir, \"Results\"))\n",
    "    save_dir = os.path.join(\n",
    "        logs_dir, f'{new_hp[\"network name\"]}_accuracy_{accuracy:.3f}.pth')\n",
    "    torch.save(model.state_dict(), save_dir)\n",
    "\n",
    "\n",
    "def Train_net_wrapper(device, which_layers, loss_function, dataloader_train, dataloader_validation, new_hp, logger, model, ChoiceOptimizer=\"Adam\", ChoiceScheduler=\"Yes\"):\n",
    "    if ChoiceOptimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=new_hp[\"learning rate\"],\n",
    "                                     betas=(new_hp[\"beta1\"],\n",
    "                                            new_hp[\"beta2\"]),\n",
    "                                     weight_decay=new_hp[\"weight decay\"],\n",
    "                                     eps=new_hp[\"epsilon\"])\n",
    "        if ChoiceScheduler == \"Yes\":\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer, step_size=new_hp[\"step size\"], gamma=new_hp[\"gamma\"])\n",
    "            train_net(model, loss_function, device, dataloader_train,\n",
    "                      dataloader_validation, optimizer, new_hp, logger, scheduler, state=which_layers, name=new_hp[\"network name\"])\n",
    "            print(f\"\\nFinished training {which_layers}!\\n\")\n",
    "        else:\n",
    "            scheduler = None\n",
    "            train_net(model, loss_function, device, dataloader_train,\n",
    "                      dataloader_validation, optimizer, new_hp, logger, scheduler, state=which_layers, name=new_hp[\"network name\"])\n",
    "            print(f\"\\nFinished training {which_layers}!\\n\")\n",
    "    elif ChoiceOptimizer == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                    lr=new_hp[\"learning rate\"],\n",
    "                                    momentum=new_hp[\"momentum\"],\n",
    "                                    weight_decay=new_hp[\"weight decay\"])\n",
    "        if ChoiceScheduler == \"Yes\":\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer, step_size=new_hp[\"step size\"], gamma=new_hp[\"gamma\"])\n",
    "            train_net(model, loss_function, device, dataloader_train,\n",
    "                      dataloader_validation, optimizer, new_hp, logger, scheduler, state=which_layers, name=new_hp[\"network name\"])\n",
    "            print(f\"\\nFinished training {which_layers}!\\n\")\n",
    "        else:\n",
    "            scheduler = None\n",
    "            train_net(model, loss_function, device, dataloader_train,\n",
    "                      dataloader_validation, optimizer, new_hp, logger, scheduler, state=which_layers, name=new_hp[\"network name\"])\n",
    "            print(f\"\\nFinished training {which_layers}!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to fine-tune the model, with the FineTuneMode.NEW_LAYERS set to train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bec20af7ee74c35a436982880b2d887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch [1/1]:   0%|                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9eb01807354c52bafcad9c189a29b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch [1/1]:   0%|                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished training NEW LAYERS!\n",
      "\n",
      "Ready to fine-tune the model, with the FineTuneMode.CLASSIFIER set to train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8e2c8d591b458eb66ab949b0b3666a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch [1/1]:   0%|                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80f9d04e7fc4d3785ea3900c4addc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch [1/1]:   0%|                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished training CLASSIFIER!\n",
      "\n",
      "Ready to fine-tune the model, with the FineTuneMode.ALL_LAYERS set to train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c75a9b6e30a454598675e02d5d850b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch [1/1]:   0%|                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372a1766b26448c2acde9bde88a78427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch [1/1]:   0%|                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished training ALL LAYERS!\n",
      "\n",
      "Got 1701/1862 with accuracy 91.353%\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Empty memory before start\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "automatic_fine_tune(hyperparameters, \"mobilenet_v3_large\", device,\n",
    "                    loss_function, train_loader, val_loader, test_loader, hyperparameters[\"optimizer\"], hyperparameters[\"scheduler\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project 1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
